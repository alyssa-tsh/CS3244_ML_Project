{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  \n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, learning_curve\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, roc_auc_score, precision_recall_curve,\n",
    "    average_precision_score, f1_score, auc\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from functions_ver2 import data_pipeline as data_pipeline_v2\n",
    "from functions import data_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb811c4",
   "metadata": {},
   "source": [
    "## Baseline model using label encoding and no hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49d7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8df47a07",
   "metadata": {},
   "source": [
    "## Using one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1bd936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Splitting data\n",
      "Total unique accounts: 45985. Starting to find cutoff point\n",
      "Cutoff month where CDF reaches 80%: -10\n",
      "\n",
      "=== Split based on CDF 80% cutoff ===\n",
      "Cutoff month: -10 (10 months ago)\n",
      "Old accounts (≤ month -10): 37,210 (80.9%)\n",
      "New accounts (> month -10): 8,775 (19.1%)\n",
      "Ratio (old/new): 4.2405\n",
      "Splitting raw credit records\n",
      "Cleaning old accounts credit records - [Length: 996586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/CS3244_ML_Project/functions.py:235: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning new accounts credit records - [Length: 51989]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/CS3244_ML_Project/functions.py:235: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n",
      "/workspaces/CS3244_ML_Project/functions.py:161: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_dropped=df_sorted.groupby('id', group_keys=False).apply(keep_row)\n",
      "/workspaces/CS3244_ML_Project/functions.py:161: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_dropped=df_sorted.groupby('id', group_keys=False).apply(keep_row)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning credit data completed\n",
      "Splitting application dataset\n",
      "Cleaning old accounts application records - [Length: (29264, 18)]\n",
      "Cleaning new accounts appplication records, - [Length: (7193, 18)]\n",
      "Encoding\n",
      "Encoders: {'name_income_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'name_education_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'name_family_status': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'name_housing_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'occupation_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False)}\n",
      "Encoding type: onehot\n",
      "Merging data\n",
      "Engineering target variable to label data\n",
      "Completed old accounts labelling\n",
      "Completed new accounts labelling\n",
      "Old accounts: (37210, 3)\n",
      "New accounts: (8775, 3)\n",
      "Old threshold: 0.20232732732732733\n",
      "New threshold: 0.5786182336182336\n",
      "Merging cleaned application and credit records\n",
      "Train shape: (29264, 63)\n",
      "Test shape: (7193, 63)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29264 entries, 0 to 29263\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                             Non-Null Count  Dtype  \n",
      "---  ------                                             --------------  -----  \n",
      " 0   id                                                 29264 non-null  int64  \n",
      " 1   cnt_children                                       29264 non-null  int64  \n",
      " 2   amt_income_total                                   29264 non-null  float64\n",
      " 3   days_birth                                         29264 non-null  int64  \n",
      " 4   days_employed                                      29264 non-null  int64  \n",
      " 5   flag_mobil                                         29264 non-null  int64  \n",
      " 6   flag_work_phone                                    29264 non-null  int64  \n",
      " 7   flag_phone                                         29264 non-null  int64  \n",
      " 8   flag_email                                         29264 non-null  int64  \n",
      " 9   cnt_fam_members                                    29264 non-null  int64  \n",
      " 10  cnt_children_encoded                               29264 non-null  int64  \n",
      " 11  cnt_fam_members_encoded                            29264 non-null  int64  \n",
      " 12  age                                                29264 non-null  int64  \n",
      " 13  age_binned_encoded                                 29264 non-null  int8   \n",
      " 14  months_employed                                    29264 non-null  int64  \n",
      " 15  years_employed                                     29264 non-null  int64  \n",
      " 16  employment_status_encoded                          29264 non-null  int64  \n",
      " 17  gender_encoded                                     29264 non-null  int64  \n",
      " 18  flag_own_realty_encoded                            29264 non-null  int64  \n",
      " 19  flag_own_car_encoded                               29264 non-null  int64  \n",
      " 20  amt_income_total_log                               29264 non-null  float64\n",
      " 21  name_income_type_Commercial associate              29264 non-null  float64\n",
      " 22  name_income_type_Pensioner                         29264 non-null  float64\n",
      " 23  name_income_type_State servant                     29264 non-null  float64\n",
      " 24  name_income_type_Student                           29264 non-null  float64\n",
      " 25  name_income_type_Working                           29264 non-null  float64\n",
      " 26  name_education_type_Academic degree                29264 non-null  float64\n",
      " 27  name_education_type_Higher education               29264 non-null  float64\n",
      " 28  name_education_type_Incomplete higher              29264 non-null  float64\n",
      " 29  name_education_type_Lower secondary                29264 non-null  float64\n",
      " 30  name_education_type_Secondary / secondary special  29264 non-null  float64\n",
      " 31  name_family_status_Civil marriage                  29264 non-null  float64\n",
      " 32  name_family_status_Married                         29264 non-null  float64\n",
      " 33  name_family_status_Separated                       29264 non-null  float64\n",
      " 34  name_family_status_Single / not married            29264 non-null  float64\n",
      " 35  name_family_status_Widow                           29264 non-null  float64\n",
      " 36  name_housing_type_Co-op apartment                  29264 non-null  float64\n",
      " 37  name_housing_type_House / apartment                29264 non-null  float64\n",
      " 38  name_housing_type_Municipal apartment              29264 non-null  float64\n",
      " 39  name_housing_type_Office apartment                 29264 non-null  float64\n",
      " 40  name_housing_type_Rented apartment                 29264 non-null  float64\n",
      " 41  name_housing_type_With parents                     29264 non-null  float64\n",
      " 42  occupation_type_Accountants                        29264 non-null  float64\n",
      " 43  occupation_type_Cleaning staff                     29264 non-null  float64\n",
      " 44  occupation_type_Cooking staff                      29264 non-null  float64\n",
      " 45  occupation_type_Core staff                         29264 non-null  float64\n",
      " 46  occupation_type_Drivers                            29264 non-null  float64\n",
      " 47  occupation_type_HR staff                           29264 non-null  float64\n",
      " 48  occupation_type_High skill tech staff              29264 non-null  float64\n",
      " 49  occupation_type_IT staff                           29264 non-null  float64\n",
      " 50  occupation_type_Laborers                           29264 non-null  float64\n",
      " 51  occupation_type_Low-skill Laborers                 29264 non-null  float64\n",
      " 52  occupation_type_Managers                           29264 non-null  float64\n",
      " 53  occupation_type_Medicine staff                     29264 non-null  float64\n",
      " 54  occupation_type_Private service staff              29264 non-null  float64\n",
      " 55  occupation_type_Realty agents                      29264 non-null  float64\n",
      " 56  occupation_type_Sales staff                        29264 non-null  float64\n",
      " 57  occupation_type_Secretaries                        29264 non-null  float64\n",
      " 58  occupation_type_Security staff                     29264 non-null  float64\n",
      " 59  occupation_type_Unemployed                         29264 non-null  float64\n",
      " 60  occupation_type_Waiters/barmen staff               29264 non-null  float64\n",
      " 61  risk_score                                         29264 non-null  float64\n",
      " 62  label                                              29264 non-null  int64  \n",
      "dtypes: float64(43), int64(19), int8(1)\n",
      "memory usage: 13.9 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7193 entries, 0 to 7192\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                             Non-Null Count  Dtype  \n",
      "---  ------                                             --------------  -----  \n",
      " 0   id                                                 7193 non-null   int64  \n",
      " 1   cnt_children                                       7193 non-null   int64  \n",
      " 2   amt_income_total                                   7193 non-null   float64\n",
      " 3   days_birth                                         7193 non-null   int64  \n",
      " 4   days_employed                                      7193 non-null   int64  \n",
      " 5   flag_mobil                                         7193 non-null   int64  \n",
      " 6   flag_work_phone                                    7193 non-null   int64  \n",
      " 7   flag_phone                                         7193 non-null   int64  \n",
      " 8   flag_email                                         7193 non-null   int64  \n",
      " 9   cnt_fam_members                                    7193 non-null   int64  \n",
      " 10  cnt_children_encoded                               7193 non-null   int64  \n",
      " 11  cnt_fam_members_encoded                            7193 non-null   int64  \n",
      " 12  age                                                7193 non-null   int64  \n",
      " 13  age_binned_encoded                                 7193 non-null   int8   \n",
      " 14  months_employed                                    7193 non-null   int64  \n",
      " 15  years_employed                                     7193 non-null   int64  \n",
      " 16  employment_status_encoded                          7193 non-null   int64  \n",
      " 17  gender_encoded                                     7193 non-null   int64  \n",
      " 18  flag_own_realty_encoded                            7193 non-null   int64  \n",
      " 19  flag_own_car_encoded                               7193 non-null   int64  \n",
      " 20  amt_income_total_log                               7193 non-null   float64\n",
      " 21  name_income_type_Commercial associate              7193 non-null   float64\n",
      " 22  name_income_type_Pensioner                         7193 non-null   float64\n",
      " 23  name_income_type_State servant                     7193 non-null   float64\n",
      " 24  name_income_type_Student                           7193 non-null   float64\n",
      " 25  name_income_type_Working                           7193 non-null   float64\n",
      " 26  name_education_type_Academic degree                7193 non-null   float64\n",
      " 27  name_education_type_Higher education               7193 non-null   float64\n",
      " 28  name_education_type_Incomplete higher              7193 non-null   float64\n",
      " 29  name_education_type_Lower secondary                7193 non-null   float64\n",
      " 30  name_education_type_Secondary / secondary special  7193 non-null   float64\n",
      " 31  name_family_status_Civil marriage                  7193 non-null   float64\n",
      " 32  name_family_status_Married                         7193 non-null   float64\n",
      " 33  name_family_status_Separated                       7193 non-null   float64\n",
      " 34  name_family_status_Single / not married            7193 non-null   float64\n",
      " 35  name_family_status_Widow                           7193 non-null   float64\n",
      " 36  name_housing_type_Co-op apartment                  7193 non-null   float64\n",
      " 37  name_housing_type_House / apartment                7193 non-null   float64\n",
      " 38  name_housing_type_Municipal apartment              7193 non-null   float64\n",
      " 39  name_housing_type_Office apartment                 7193 non-null   float64\n",
      " 40  name_housing_type_Rented apartment                 7193 non-null   float64\n",
      " 41  name_housing_type_With parents                     7193 non-null   float64\n",
      " 42  occupation_type_Accountants                        7193 non-null   float64\n",
      " 43  occupation_type_Cleaning staff                     7193 non-null   float64\n",
      " 44  occupation_type_Cooking staff                      7193 non-null   float64\n",
      " 45  occupation_type_Core staff                         7193 non-null   float64\n",
      " 46  occupation_type_Drivers                            7193 non-null   float64\n",
      " 47  occupation_type_HR staff                           7193 non-null   float64\n",
      " 48  occupation_type_High skill tech staff              7193 non-null   float64\n",
      " 49  occupation_type_IT staff                           7193 non-null   float64\n",
      " 50  occupation_type_Laborers                           7193 non-null   float64\n",
      " 51  occupation_type_Low-skill Laborers                 7193 non-null   float64\n",
      " 52  occupation_type_Managers                           7193 non-null   float64\n",
      " 53  occupation_type_Medicine staff                     7193 non-null   float64\n",
      " 54  occupation_type_Private service staff              7193 non-null   float64\n",
      " 55  occupation_type_Realty agents                      7193 non-null   float64\n",
      " 56  occupation_type_Sales staff                        7193 non-null   float64\n",
      " 57  occupation_type_Secretaries                        7193 non-null   float64\n",
      " 58  occupation_type_Security staff                     7193 non-null   float64\n",
      " 59  occupation_type_Unemployed                         7193 non-null   float64\n",
      " 60  occupation_type_Waiters/barmen staff               7193 non-null   float64\n",
      " 61  risk_score                                         7193 non-null   float64\n",
      " 62  label                                              7193 non-null   int64  \n",
      "dtypes: float64(43), int64(19), int8(1)\n",
      "memory usage: 3.4 MB\n",
      "None\n",
      "Completed X, y split\n",
      "Final train and test processing completed generated successfully\n"
     ]
    }
   ],
   "source": [
    "X_train_std, y_train, X_test_std, y_test = data_pipeline('onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3669f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_components(X_train, method=\"default\"):\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train)\n",
    "    explained_var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "    if method == \"avg\":\n",
    "        avg_var = 1 / len(explained_var_ratio)\n",
    "        optimal_components = np.sum(explained_var_ratio > avg_var)\n",
    "\n",
    "    elif method == \"elbow\":\n",
    "        diffs = np.diff(explained_var_ratio)\n",
    "        elbow_idx = np.argmax(diffs * -1) + 1 \n",
    "        optimal_components = elbow_idx\n",
    "\n",
    "    elif method == \"cumulative\":\n",
    "        cum_var = np.cumsum(explained_var_ratio)\n",
    "        optimal_components = np.argmax(cum_var >= 0.95) + 1\n",
    "\n",
    "    else:\n",
    "        optimal_components = None\n",
    "    return optimal_components\n",
    "\n",
    "\n",
    "def build_knn_pipeline(pca_components=None, pca_method='default', sampling_method='smote', random_state=42):\n",
    "    \n",
    "    steps = []\n",
    "    \n",
    "    if sampling_method:\n",
    "        sampler_map = {\n",
    "            'smote': SMOTE(random_state=random_state),\n",
    "            'smotetomek': SMOTETomek(random_state=random_state),\n",
    "            'cc': ClusterCentroids(random_state=random_state)\n",
    "        }\n",
    "        steps.append(('sampling', sampler_map[sampling_method.lower()]))\n",
    "\n",
    "    if pca_method == 'default' or pca_components is None:\n",
    "        steps.append(('pca', PCA(whiten=True, random_state=random_state)))\n",
    "    else:\n",
    "        steps.append(('pca', PCA(n_components=pca_components, whiten=True, random_state=random_state)))\n",
    "    \n",
    "    steps.append(('knn', KNeighborsClassifier()))\n",
    "    \n",
    "    pipeline_cls = ImbPipeline if sampling_method else Pipeline\n",
    "    pipeline = pipeline_cls(steps)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def tune_knn_pipeline(pipeline, X_train, y_train, param_grid, cv=3, scoring='f1', n_jobs=-1):\n",
    "    grid = GridSearchCV(pipeline, param_grid=param_grid, cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_, grid.best_params_\n",
    "\n",
    "\n",
    "def evaluate_and_plot(best_model, X_test, y_test, method_name='best'):\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute PR curve for PR-AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    results = {\n",
    "        'test_f1': f1_score(y_test, y_pred),\n",
    "        'test_roc_auc': roc_auc_score(y_test, y_proba),\n",
    "        'test_ap': average_precision_score(y_test, y_proba),\n",
    "        'test_pr_auc': pr_auc,  \n",
    "        'classification_report': classification_report(y_test, y_pred, digits=3),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "def model_pipeline_knn_pca(\n",
    "    X_train, y_train, X_test=None, y_test=None,\n",
    "    n_splits=5, random_state=42,\n",
    "    pca_method='default', sampling_method=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Full model pipeline: KNN + PCA + (optional) sampling.\n",
    "    Performs CV for hyperparameter tuning and evaluates best model.\n",
    "    \"\"\"\n",
    "    \n",
    "    knn_param_grid = {\n",
    "        'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "        'knn__metric': ['euclidean', 'minkowski', 'manhattan']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nStarting PCA+KNN pipeline ({'Base' if sampling_method is None else sampling_method.upper()})\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    fold_models, f1_scores, roc_scores, pr_auc_scores = [], [], [], []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        components = get_n_components(X_tr, method=pca_method)\n",
    "        pipeline = build_knn_pipeline(\n",
    "            pca_components=components,\n",
    "            pca_method=pca_method,\n",
    "            sampling_method=sampling_method,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        best_pipeline, best_params = tune_knn_pipeline(pipeline, X_tr, y_tr, knn_param_grid, cv=3)\n",
    "        \n",
    "        y_pred = best_pipeline.predict(X_val)\n",
    "        y_proba = best_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        roc = roc_auc_score(y_val, y_proba)\n",
    "        pr_auc = average_precision_score(y_val, y_proba)\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "        roc_scores.append(roc)\n",
    "        pr_auc_scores.append(pr_auc)\n",
    "        fold_models.append(best_pipeline)\n",
    "        \n",
    "        print(f\"Fold {fold}: n_components={components}, Best Params={best_params}, \"\n",
    "              f\"F1={f1:.3f}, ROC-AUC={roc:.3f}, PR-AUC={pr_auc:.3f}\")\n",
    "    \n",
    "    # Select best fold by F1\n",
    "    best_fold_idx = int(np.argmax(f1_scores))\n",
    "    best_model = fold_models[best_fold_idx]\n",
    "    \n",
    "    print(f\"\\nBest fold selected: Fold {best_fold_idx+1} \"\n",
    "          f\"(F1={f1_scores[best_fold_idx]:.3f}, ROC-AUC={roc_scores[best_fold_idx]:.3f}, \"\n",
    "          f\"PR-AUC={pr_auc_scores[best_fold_idx]:.3f})\")\n",
    "\n",
    "    results = {\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'roc_auc': np.mean(roc_scores),\n",
    "        'pr_auc': np.mean(pr_auc_scores),\n",
    "        'n_components': components,\n",
    "        'best_fold_idx': best_fold_idx\n",
    "    }\n",
    "\n",
    "    # Test evaluation\n",
    "    if X_test is not None and y_test is not None:\n",
    "        test_results = evaluate_and_plot(best_model, X_test, y_test, method_name=pca_method)\n",
    "        results.update(test_results)\n",
    "\n",
    "        print(f\"\\nTest set → F1={results['test_f1']:.3f}, \"\n",
    "              f\"ROC-AUC={results['test_roc_auc']:.3f}, \"\n",
    "              f\"PR-AUC={results['test_ap']:.3f}\")\n",
    "\n",
    "    return results, best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208fdb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_model(X_train, y_train, X_test, y_test, random_state=42):\n",
    "    sampling_methods = [None, 'smote', 'smotetomek', 'cc']\n",
    "    train_summary, test_summary = [], []\n",
    "\n",
    "    for method in sampling_methods:\n",
    "        method_name = \"Base\" if method is None else method.upper()\n",
    "        print(f\"\\n{'='*70}\\nRunning {method_name} Sampling Method Model\\n{'='*70}\")\n",
    "\n",
    "        res, best_model = model_pipeline_knn_pca(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            pca_method='default',\n",
    "            sampling_method=method,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        train_summary.append({\n",
    "            \"Method\": method_name,\n",
    "            \"F1 (Train)\": res.get('f1', None),\n",
    "            \"ROC-AUC (Train)\": res.get('roc_auc', None),\n",
    "            \"PR-AUC (Train)\": res.get('ap', None)\n",
    "        })\n",
    "\n",
    "        test_summary.append({\n",
    "            \"Method\": method_name,\n",
    "            \"F1 (Test)\": res.get('test_f1', None),\n",
    "            \"ROC-AUC (Test)\": res.get('test_roc_auc', None),\n",
    "            \"PR-AUC (Test)\": res.get('test_ap', None)\n",
    "        })\n",
    "\n",
    "    \n",
    "    df_train = pd.DataFrame(train_summary).sort_values(by=\"F1 (Train)\", ascending=False).reset_index(drop=True)\n",
    "    df_test = pd.DataFrame(test_summary).sort_values(by=\"F1 (Test)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    print(\"\\n\\n================ TRAIN PERFORMANCE SUMMARY ================\\n\")\n",
    "    print(df_train[[\"Method\", \"F1 (Train)\", \"ROC-AUC (Train)\", \"PR-AUC (Train)\"]].to_string(index=False))\n",
    "\n",
    "    \n",
    "    print(\"\\n\\n================ TEST PERFORMANCE SUMMARY ================\\n\")\n",
    "    print(df_test[[\"Method\", \"F1 (Test)\", \"ROC-AUC (Test)\", \"PR-AUC (Test)\"]].to_string(index=False))\n",
    "\n",
    "    \n",
    "    best_method = df_test.iloc[0][\"Method\"]\n",
    "    best_test_f1 = df_test.iloc[0][\"F1 (Test)\"]\n",
    "    best_test_roc = df_test.iloc[0][\"ROC-AUC (Test)\"]\n",
    "    best_test_pr = df_test.iloc[0][\"PR-AUC (Test)\"]\n",
    "\n",
    "    print(f\"\\nBest Model (by Test F1): {best_method} → \"\n",
    "          f\"F1={best_test_f1:.3f}, ROC-AUC={best_test_roc:.3f}, PR-AUC={best_test_pr:.3f}\")\n",
    "\n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c61ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pca_feature_importance(best_model, X_train, y_train, top_n_features=10, top_n_pcs=5):\n",
    "    \n",
    "    pca_step_name = [name for name in best_model.named_steps if 'pca' in name.lower()][0]\n",
    "    pca_step = best_model.named_steps[pca_step_name]\n",
    "    \n",
    "    loadings = pd.DataFrame(\n",
    "        pca_step.components_.T,\n",
    "        index=X_train.columns,\n",
    "        columns=[f'PC{i+1}' for i in range(pca_step.n_components_)]\n",
    "    )\n",
    "    loadings['importance'] = np.sum(np.abs(loadings), axis=1)\n",
    "    loadings = loadings.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top features by PCA importance:\\n\", loadings.head(top_n_features))\n",
    "    \n",
    "    # --- Transform X_train to PCA space ---\n",
    "    X_pca = pca_step.transform(X_train)\n",
    "    X_pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(pca_step.n_components_)])\n",
    "    X_pca_df['label'] = y_train.values\n",
    "    \n",
    "    # --- Correlation of PCs with label ---\n",
    "    corr_with_label = X_pca_df.drop(columns='label').corrwith(X_pca_df['label']).abs().sort_values(ascending=False)\n",
    "    \n",
    "    # --- Heatmap of top features × all PCs ---\n",
    "    top_features = loadings.head(top_n_features).index\n",
    "    loadings_top_features = loadings.loc[top_features, loadings.columns[:-1]] \n",
    "    loadings_scaled = loadings_top_features.apply(lambda x: x / np.max(np.abs(x)), axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(min(20, pca_step.n_components_*1.5),6))\n",
    "    sns.heatmap(loadings_scaled, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title(f\"PCA Loadings (Top {top_n_features} Features)\")\n",
    "    plt.xlabel(\"Principal Components\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- Barplot of top PCs by correlation with label ---\n",
    "    top_pcs = corr_with_label.head(top_n_pcs).index\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.barplot(x=top_pcs, y=corr_with_label[top_pcs])\n",
    "    plt.ylabel(\"Absolute correlation with label\")\n",
    "    plt.title(f\"Top {top_n_pcs} PCs Correlated with Label\")\n",
    "    plt.show()\n",
    "    \n",
    "    return loadings, corr_with_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0075b4d",
   "metadata": {},
   "source": [
    "### Resample In Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00115e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Running Base Sampling Method Model\n",
      "======================================================================\n",
      "\n",
      "Starting PCA+KNN pipeline (Base)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_train, result_test = run_knn_model(X_train_std, y_train, X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9362aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top features and PCs\n",
    "loadings, corr_with_label = visualize_pca_feature_importance(\n",
    "    best_model, X_train_std, y_train,\n",
    "    top_n_features=10, top_n_pcs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671a8fd",
   "metadata": {},
   "source": [
    "## Final performance on Test Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

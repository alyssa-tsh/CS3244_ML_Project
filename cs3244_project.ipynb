{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyssa-tsh/CS3244_ML_Project/blob/main/cs3244_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1U29HV8DBvCi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from functions import data_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rikdifos/credit-card-approval-prediction?dataset_version_number=3&file_name=application_record.csv...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3.04M/3.04M [00:01<00:00, 2.48MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting zip of application_record.csv...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rikdifos/credit-card-approval-prediction?dataset_version_number=3&file_name=credit_record.csv...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.28M/2.28M [00:01<00:00, 1.97MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting zip of credit_record.csv...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting data\n",
            "Total unique accounts: 45985. Starting to find cutoff point\n",
            "Cutoff month where CDF reaches 80%: -10\n",
            "\n",
            "=== Split based on CDF 80% cutoff ===\n",
            "Cutoff month: -10 (10 months ago)\n",
            "Old accounts (≤ month -10): 37,210 (80.9%)\n",
            "New accounts (> month -10): 8,775 (19.1%)\n",
            "Ratio (old/new): 4.2405\n",
            "Splitting raw credit records\n",
            "Cleaning old accounts credit records - [Length: 996586]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/functions.py:174: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning new accounts credit records - [Length: 51989]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/functions.py:174: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n",
            "/workspaces/CS3244_ML_Project/functions.py:81: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_dropped=df_sorted.groupby('id', group_keys=False).apply(keep_row)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning credit data completed\n",
            "Splitting application dataset\n",
            "Starting to clean application records\n",
            "Dropping object columns\n",
            "Completed cleaning raw application records\n",
            "Merging data\n",
            "Engineering target variable to label data\n",
            "Completed old accounts labelling\n",
            "Completed new accounts labelling\n",
            "Old accounts: (37210, 3)\n",
            "New accounts: (8775, 3)\n",
            "Old threshold: 0.19907407407407407\n",
            "New threshold: 0.5786182336182336\n",
            "Merging cleaned application and credit records\n",
            "Train shape: (29264, 28)\n",
            "Test shape: (7193, 28)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29264 entries, 0 to 29263\n",
            "Data columns (total 28 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   id                           29264 non-null  int64  \n",
            " 1   cnt_children                 29264 non-null  int64  \n",
            " 2   amt_income_total             29264 non-null  float64\n",
            " 3   days_birth                   29264 non-null  int64  \n",
            " 4   days_employed                29264 non-null  int64  \n",
            " 5   flag_mobil                   29264 non-null  int64  \n",
            " 6   flag_work_phone              29264 non-null  int64  \n",
            " 7   flag_phone                   29264 non-null  int64  \n",
            " 8   flag_email                   29264 non-null  int64  \n",
            " 9   cnt_fam_members              29264 non-null  int64  \n",
            " 10  cnt_children_encoded         29264 non-null  int64  \n",
            " 11  age                          29264 non-null  int64  \n",
            " 12  age_binned_encoded           29264 non-null  int64  \n",
            " 13  months_employed              29264 non-null  int64  \n",
            " 14  years_employed               29264 non-null  int64  \n",
            " 15  employment_status_encoded    29264 non-null  int64  \n",
            " 16  cnt_fam_members_encoded      29264 non-null  int64  \n",
            " 17  name_income_type_encoded     29264 non-null  int64  \n",
            " 18  name_education_type_encoded  29264 non-null  int64  \n",
            " 19  name_family_status_encoded   29264 non-null  int64  \n",
            " 20  name_housing_type_encoded    29264 non-null  int64  \n",
            " 21  occupation_type_encoded      29264 non-null  int64  \n",
            " 22  gender_encoded               29264 non-null  int64  \n",
            " 23  flag_own_realty_encoded      29264 non-null  int64  \n",
            " 24  flag_own_car_encoded         29264 non-null  int64  \n",
            " 25  amt_income_total_log         29264 non-null  float64\n",
            " 26  risk_score                   29264 non-null  float64\n",
            " 27  label                        29264 non-null  int64  \n",
            "dtypes: float64(3), int64(25)\n",
            "memory usage: 6.3 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7193 entries, 0 to 7192\n",
            "Data columns (total 28 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   id                           7193 non-null   int64  \n",
            " 1   cnt_children                 7193 non-null   int64  \n",
            " 2   amt_income_total             7193 non-null   float64\n",
            " 3   days_birth                   7193 non-null   int64  \n",
            " 4   days_employed                7193 non-null   int64  \n",
            " 5   flag_mobil                   7193 non-null   int64  \n",
            " 6   flag_work_phone              7193 non-null   int64  \n",
            " 7   flag_phone                   7193 non-null   int64  \n",
            " 8   flag_email                   7193 non-null   int64  \n",
            " 9   cnt_fam_members              7193 non-null   int64  \n",
            " 10  cnt_children_encoded         7193 non-null   int64  \n",
            " 11  age                          7193 non-null   int64  \n",
            " 12  age_binned_encoded           7193 non-null   int64  \n",
            " 13  months_employed              7193 non-null   int64  \n",
            " 14  years_employed               7193 non-null   int64  \n",
            " 15  employment_status_encoded    7193 non-null   int64  \n",
            " 16  cnt_fam_members_encoded      7193 non-null   int64  \n",
            " 17  name_income_type_encoded     7193 non-null   int64  \n",
            " 18  name_education_type_encoded  7193 non-null   int64  \n",
            " 19  name_family_status_encoded   7193 non-null   int64  \n",
            " 20  name_housing_type_encoded    7193 non-null   int64  \n",
            " 21  occupation_type_encoded      7193 non-null   int64  \n",
            " 22  gender_encoded               7193 non-null   int64  \n",
            " 23  flag_own_realty_encoded      7193 non-null   int64  \n",
            " 24  flag_own_car_encoded         7193 non-null   int64  \n",
            " 25  amt_income_total_log         7193 non-null   float64\n",
            " 26  risk_score                   7193 non-null   float64\n",
            " 27  label                        7193 non-null   int64  \n",
            "dtypes: float64(3), int64(25)\n",
            "memory usage: 1.5 MB\n",
            "None\n",
            "Final train and test processing completed generated successfully\n"
          ]
        }
      ],
      "source": [
        "train, test = data_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer \n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_n_components(X_train, method = \"avg\"):\n",
        "        pca = PCA()\n",
        "        pca.fit(X_train)\n",
        "        explained_var_ratio = pca.explained_variance_ratio_\n",
        "        if method == \"avg\":\n",
        "            avg_var = 1 / len(explained_var_ratio)\n",
        "            optimal_components = np.sum(explained_var_ratio > avg_var)\n",
        "\n",
        "        elif method == \"elbow\":\n",
        "            diffs = np.diff(explained_var_ratio)\n",
        "            elbow_idx = np.argmax(diffs * -1) + 1 \n",
        "            optimal_components = elbow_idx\n",
        "\n",
        "        elif method == \"cumulative\":\n",
        "            cum_var = np.cumsum(explained_var_ratio)\n",
        "            optimal_components = np.argmax(cum_var >= 0.95) + 1\n",
        "        else:\n",
        "            # comparison with a base model to see if PCA methods are actually improving the model\n",
        "            optimal_components = None\n",
        "        return optimal_components\n",
        "    \n",
        "methods = [\"avg\", \"elbow\", \"cumulative\", \"default\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformations & Scaling\n",
        "- from QQ plot analysis - noticed that certain numerical features require transformation and diff features need different scalers\n",
        "> Highly skewed & outlier-heavy\trisk_score, months_employed\t→ YeoJohnsonTransformer() or np.log1p() → RobustScaler\n",
        "\n",
        "> Already normal/log-transformed\tamt_income_total_log, age\t→ StandardScaler\n",
        "\n",
        "> Discrete / ordinal numeric\tcnt_children, cnt_fam_members\t→ Keep as is or encode as ordinal integers\n",
        "\n",
        "### Encoding\n",
        "* REALIZED that there are a lot of categorical features - label encoder might assign encoded categories some inherent ordering affecting model which is fine for tree based models but not for SVC and XGboost\n",
        "| Feature type                  | XGBoost                     | SVC          | KNN                       |\n",
        "| ----------------------------- | --------------------------- | ------------ | ------------------------- |\n",
        "| Binary                        | 0/1 mapping                 | 0/1 mapping  | 0/1 mapping               |\n",
        "| Low-cardinality (<5)          | One-hot or label encoding   | One-hot only | One-hot                   |\n",
        "| Medium/high-cardinality (~17) | Frequency or label encoding | One-hot only | One-hot / binary encoding |\n",
        "| Numeric                       | Raw                         | Standardized | Standardized              |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_features(df, target_col=None, encoders=None):\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "    \n",
        "    df_encoded = df.copy()\n",
        "    \n",
        "    # Define your columns\n",
        "    binary_cols = [\"code_gender\", \"flag_own_realty\", \"flag_own_car\"]\n",
        "    low_card_cols = [\"name_income_type\", \"name_education_type\", \"name_family_status\", \"name_housing_type\"]\n",
        "    high_card_cols = [\"occupation_type\", \"age_binned\"]\n",
        "    \n",
        "    # ---- Binary mapping ----\n",
        "    for col in binary_cols:\n",
        "        mapping = {'M':0, 'F':1, 'Y':1, 'N':0}\n",
        "        df_encoded[col+\"_encoded\"] = df_encoded[col].map(mapping)\n",
        "    \n",
        "    # ---- One-hot encoding for low-cardinality ----\n",
        "    for col in low_card_cols:\n",
        "        if col not in encoders:\n",
        "            ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "            ohe.fit(df_encoded[[col]])\n",
        "            encoders[col] = ohe\n",
        "        else:\n",
        "            ohe = encoders[col]\n",
        "        \n",
        "        cols_encoded = pd.DataFrame(ohe.transform(df_encoded[[col]]),\n",
        "                                    columns=[f\"{col}_{c}\" for c in ohe.categories_[0]],\n",
        "                                    index=df_encoded.index)\n",
        "        df_encoded = pd.concat([df_encoded, cols_encoded], axis=1)\n",
        "    \n",
        "    # ---- Target encoding for high-cardinality ----\n",
        "    for col in high_card_cols:\n",
        "        if col not in encoders:\n",
        "            if target_col is None:\n",
        "                raise ValueError(f\"Target column must be provided for training target encoding on {col}\")\n",
        "            te = TargetEncoder()\n",
        "            te.fit(df_encoded[[col]], df_encoded[target_col])\n",
        "            encoders[col] = te\n",
        "        else:\n",
        "            te = encoders[col]\n",
        "        \n",
        "        df_encoded[col+\"_encoded\"] = te.transform(df_encoded[[col]])\n",
        "    \n",
        "    # ---- Drop original object columns ----\n",
        "    object_cols = df_encoded.select_dtypes('object').columns\n",
        "    df_encoded.drop(columns=object_cols, inplace=True)\n",
        "    \n",
        "    return df_encoded, encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_pipeline(train_df, test_df, target_col, numeric_cols, categorical_cols=None, random_state=42):\n",
        "\n",
        "    # drop highly correlated features - keeping months employed \n",
        "    # assigning numeric_cols specific scalers and transformations based on QQ plot analysis\n",
        "    skewed = ['risk_score', 'months_employed']\n",
        "    normal = ['amt_income_total_log', 'age']\n",
        "    discrete = ['cnt_children', 'cnt_fam_members']\n",
        "    drop_cols = [\"days_birth\", \"amt_income_total\", \"years_employed\", \"flag_mobil\"]\n",
        "\n",
        "\n",
        "    train_df = train_df.drop(columns=drop_cols)\n",
        "    test_df = test_df.drop(columns=drop_cols)\n",
        "\n",
        "    train = train_df.copy()\n",
        "    test = test_df.copy()\n",
        "\n",
        "    # train test split\n",
        "    X_train_full = train.drop(columns=[target_col])\n",
        "    y_train_full = train[target_col]\n",
        "    X_test = test.drop(columns=[target_col])\n",
        "    y_test = test[target_col]\n",
        "\n",
        "    # Using RobustScaler instead since from EDA Standard & Min-Max Scaler distorted by outliers\n",
        "    preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('skewed', Pipeline([\n",
        "            ('yeo', PowerTransformer(method='yeo-johnson')),\n",
        "            ('robust', RobustScaler())\n",
        "        ]), skewed),\n",
        "        \n",
        "        ('normal', StandardScaler(), normal),\n",
        "        \n",
        "        # No scaling required for discrete features\n",
        "        ('discrete', 'passthrough', discrete)\n",
        "\n",
        "    ]\n",
        "\n",
        "    low_card_cols = [\"name_income_type\",\"name_education_type\",\"name_family_status\",\"name_housing_type\",\"age_binned\"]\n",
        "    high_card_cols = [\"occupation_type\"]\n",
        "\n",
        "    xgb_preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", \"passthrough\", numeric_cols),\n",
        "            (\"low_cat\", OneHotEncoder(handle_unknown='ignore'), low_card_cols),\n",
        "            (\"high_cat\", FunctionTransformer(lambda X: X.assign(**{col: X[col].map(X[col].value_counts(normalize=True)) \n",
        "                                                                for col in high_card_cols})), high_card_cols)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    xgb_pipeline = Pipeline([\n",
        "        (\"preprocessor\", xgb_preprocessor),\n",
        "        (\"classifier\", XGBClassifier())\n",
        "    ])\n",
        "\n",
        "    # Example for SVC\n",
        "    svc_preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", StandardScaler(), numeric_cols),\n",
        "            (\"cat\", OneHotEncoder(handle_unknown='ignore'), low_card_cols + high_card_cols)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    svc_pipeline = Pipeline([\n",
        "        (\"preprocessor\", svc_preprocessor),\n",
        "        (\"classifier\", SVC(probability=True))\n",
        "    ])\n",
        "\n",
        "    \n",
        ")\n",
        "\n",
        "    # Define models\n",
        "    models = {\n",
        "        \"SVM (Linear)\": SVC(kernel=\"linear\", random_state=random_state),\n",
        "        \"XGB Classifier\" : XGBClassifier(use_label_encoder=True, eval_metric=\"logloss\", random_state=random_state)\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"Training model: {name} with StratifiedKFold...\")\n",
        "        acc_scores, f1_scores, roc_scores = [], [], []\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full), 1):\n",
        "            X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
        "            y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
        "\n",
        "            pipeline = Pipeline([\n",
        "                (\"preprocess\", preprocessor),\n",
        "                (\"classifier\", model)\n",
        "            ])\n",
        "            pipeline.fit(X_train, y_train)\n",
        "\n",
        "            y_pred = pipeline.predict(X_val)\n",
        "            y_proba = pipeline.predict_proba(X_val)[:,1] if hasattr(pipeline, \"predict_proba\") else None\n",
        "\n",
        "            acc_scores.append(accuracy_score(y_val, y_pred))\n",
        "            f1_scores.append(f1_score(y_val, y_pred))\n",
        "            roc_scores.append(roc_auc_score(y_val, y_proba) if y_proba is not None else np.nan)\n",
        "\n",
        "            print(f\"Fold {fold}: Accuracy={acc_scores[-1]:.3f}, F1={f1_scores[-1]:.3f}, ROC-AUC={roc_scores[-1]:.3f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"model\": name,\n",
        "            \"accuracy\": np.mean(acc_scores),\n",
        "            \"f1_score\": np.mean(f1_scores),\n",
        "            \"roc_auc\": np.nanmean(roc_scores)\n",
        "        })\n",
        "        print(f\"Finished training {name} across all folds.\\n\")\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values(by=\"f1_score\", ascending=False)\n",
        "\n",
        "    return results_df, X_train_full, y_train_full, X_test, y_test\n",
        "\n",
        "\n",
        "target_col = \"label\"\n",
        "results_df, X_train, y_train, X_test, y_test = model_pipeline(\n",
        "    train, test, target_col, numeric_cols\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPVW1WKkh1bEXudRF2QGP07",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyssa-tsh/CS3244_ML_Project/blob/main/cs3244_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1U29HV8DBvCi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'functions_ver2'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_pipeline\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctions_ver2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_pipeline \u001b[38;5;28;01mas\u001b[39;00m data_pipeline_v2\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'functions_ver2'"
          ]
        }
      ],
      "source": [
        "from functions import data_pipeline\n",
        "from functions_ver2 import data_pipeline as data_pipeline_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data\n",
            "Splitting credits data\n",
            "Total unique accounts: 45985. Starting to find cutoff point\n",
            "Cutoff month where CDF reaches 80%: -10\n",
            "\n",
            "=== Split based on CDF 80% cutoff ===\n",
            "Cutoff month: -10 (10 months ago)\n",
            "Old accounts (â‰¤ month -10): 37,210 (80.9%)\n",
            "New accounts (> month -10): 8,775 (19.1%)\n",
            "Ratio (old/new): 4.2405\n",
            "Splitting raw credit records\n",
            "Cleaning old accounts credit records - [Length: 996586]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/functions.py:169: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning new accounts credit records - [Length: 51989]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/functions.py:169: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n",
            "/workspaces/CS3244_ML_Project/functions.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_dropped=df_sorted.groupby('id', group_keys=False).apply(keep_row)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning credit data completed\n",
            "Splitting applications data\n",
            "Cleaning old application records\n",
            "Cleaning new application records\n",
            "Merging data\n",
            "Engineering target variable to label data\n",
            "Completed old accounts labelling\n",
            "Completed new accounts labelling\n",
            "Old accounts: (37210, 3)\n",
            "New accounts: (8775, 3)\n",
            "Old threshold: 0.19732232232232233\n",
            "New threshold: 0.5786182336182336\n",
            "Merging cleaned application and credit records\n",
            "Train shape: (29264, 28)\n",
            "Test shape: (7193, 28)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29264 entries, 0 to 29263\n",
            "Data columns (total 28 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   id                           29264 non-null  int64  \n",
            " 1   cnt_children                 29264 non-null  int64  \n",
            " 2   amt_income_total             29264 non-null  float64\n",
            " 3   days_birth                   29264 non-null  int64  \n",
            " 4   days_employed                29264 non-null  int64  \n",
            " 5   flag_mobil                   29264 non-null  int64  \n",
            " 6   flag_work_phone              29264 non-null  int64  \n",
            " 7   flag_phone                   29264 non-null  int64  \n",
            " 8   flag_email                   29264 non-null  int64  \n",
            " 9   cnt_fam_members              29264 non-null  int64  \n",
            " 10  cnt_children_encoded         29264 non-null  int64  \n",
            " 11  age                          29264 non-null  int64  \n",
            " 12  months_employed              29264 non-null  int64  \n",
            " 13  years_employed               29264 non-null  int64  \n",
            " 14  employment_status_encoded    29264 non-null  int64  \n",
            " 15  cnt_fam_members_encoded      29264 non-null  int64  \n",
            " 16  name_income_type_encoded     29264 non-null  int64  \n",
            " 17  name_education_type_encoded  29264 non-null  int64  \n",
            " 18  name_family_status_encoded   29264 non-null  int64  \n",
            " 19  name_housing_type_encoded    29264 non-null  int64  \n",
            " 20  occupation_type_encoded      29264 non-null  int64  \n",
            " 21  age_binned_encoded           29264 non-null  int64  \n",
            " 22  code_gender_encoded          29264 non-null  int64  \n",
            " 23  flag_own_realty_encoded      29264 non-null  int64  \n",
            " 24  flag_own_car_encoded         29264 non-null  int64  \n",
            " 25  amt_income_total_log         29264 non-null  float64\n",
            " 26  risk_score                   29264 non-null  float64\n",
            " 27  label                        29264 non-null  int64  \n",
            "dtypes: float64(3), int64(25)\n",
            "memory usage: 6.3 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7193 entries, 0 to 7192\n",
            "Data columns (total 28 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   id                           7193 non-null   int64  \n",
            " 1   cnt_children                 7193 non-null   int64  \n",
            " 2   amt_income_total             7193 non-null   float64\n",
            " 3   days_birth                   7193 non-null   int64  \n",
            " 4   days_employed                7193 non-null   int64  \n",
            " 5   flag_mobil                   7193 non-null   int64  \n",
            " 6   flag_work_phone              7193 non-null   int64  \n",
            " 7   flag_phone                   7193 non-null   int64  \n",
            " 8   flag_email                   7193 non-null   int64  \n",
            " 9   cnt_fam_members              7193 non-null   int64  \n",
            " 10  cnt_children_encoded         7193 non-null   int64  \n",
            " 11  age                          7193 non-null   int64  \n",
            " 12  months_employed              7193 non-null   int64  \n",
            " 13  years_employed               7193 non-null   int64  \n",
            " 14  employment_status_encoded    7193 non-null   int64  \n",
            " 15  cnt_fam_members_encoded      7193 non-null   int64  \n",
            " 16  name_income_type_encoded     7193 non-null   int64  \n",
            " 17  name_education_type_encoded  7193 non-null   int64  \n",
            " 18  name_family_status_encoded   7193 non-null   int64  \n",
            " 19  name_housing_type_encoded    7193 non-null   int64  \n",
            " 20  occupation_type_encoded      7193 non-null   int64  \n",
            " 21  age_binned_encoded           7193 non-null   int64  \n",
            " 22  code_gender_encoded          7193 non-null   int64  \n",
            " 23  flag_own_realty_encoded      7193 non-null   int64  \n",
            " 24  flag_own_car_encoded         7193 non-null   int64  \n",
            " 25  amt_income_total_log         7193 non-null   float64\n",
            " 26  risk_score                   7193 non-null   float64\n",
            " 27  label                        7193 non-null   int64  \n",
            "dtypes: float64(3), int64(25)\n",
            "memory usage: 1.5 MB\n",
            "None\n",
            "Final train and test processing completed generated successfully\n"
          ]
        }
      ],
      "source": [
        "train, test = data_pipeline(model_name='XGB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_n_components(X_train, method = \"avg\"):\n",
        "        pca = PCA()\n",
        "        pca.fit(X_train)\n",
        "        explained_var_ratio = pca.explained_variance_ratio_\n",
        "        if method == \"avg\":\n",
        "            avg_var = 1 / len(explained_var_ratio)\n",
        "            optimal_components = np.sum(explained_var_ratio > avg_var)\n",
        "\n",
        "        elif method == \"elbow\":\n",
        "            diffs = np.diff(explained_var_ratio)\n",
        "            elbow_idx = np.argmax(diffs * -1) + 1 \n",
        "            optimal_components = elbow_idx\n",
        "\n",
        "        elif method == \"cumulative\":\n",
        "            cum_var = np.cumsum(explained_var_ratio)\n",
        "            optimal_components = np.argmax(cum_var >= 0.95) + 1\n",
        "        else:\n",
        "            # comparison with a base model to see if PCA methods are actually improving the model\n",
        "            optimal_components = None\n",
        "        return optimal_components\n",
        "    \n",
        "methods = [\"avg\", \"elbow\", \"cumulative\", \"default\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformations & Scaling\n",
        "- from QQ plot analysis - noticed that certain numerical features require transformation and diff features need different scalers\n",
        "> Highly skewed & outlier-heavy\trisk_score, months_employed\tâ†’ YeoJohnsonTransformer() or np.log1p() â†’ RobustScaler\n",
        "\n",
        "> Already normal/log-transformed\tamt_income_total_log, age\tâ†’ StandardScaler\n",
        "\n",
        "> Discrete / ordinal numeric\tcnt_children, cnt_fam_members\tâ†’ Keep as is or encode as ordinal integers\n",
        "\n",
        "### Encoding\n",
        "* categorical features - label encoder might assign encoded categories some inherent ordering affecting model which is fine for tree based models & XGBoost but not for SVC and KNN, so need to use diff encoding methods that suit the diff models\n",
        "\n",
        "| Feature type                  | XGBoost                     | SVC          | KNN                       |\n",
        "| ----------------------------- | --------------------------- | ------------ | ------------------------- |\n",
        "| Binary                        | 0/1 mapping                 | 0/1 mapping  | 0/1 mapping               |\n",
        "| Low-cardinality (<5)          | One-hot or label encoding   | One-hot only | One-hot                   |\n",
        "| Medium/high-cardinality (~17) | Frequency or label encoding | One-hot only | One-hot / binary encoding |\n",
        "| Numeric                       | Raw                         | Standardized | Standardized              |\n",
        "\n",
        "## Dropping of correlated features\n",
        "| Feature type     | XGBoost / Tree                      | SVC / KNN / Linear                |\n",
        "| ---------------- | ----------------------------------- | --------------------------------- |\n",
        "| Discrete numeric | keep numeric                        | Better as categorical / one-hot   |\n",
        "| Binned/ordinal   | Optional (tree can handle either)   | Use one-hot encoding              |\n",
        "\n",
        "## Feature Selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import (\n",
        "    PowerTransformer, RobustScaler, StandardScaler,\n",
        "    OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif, RFE, SelectFromModel\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Column Dictionary\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "numeric_cols = [\"age\", \"cnt_children\", \"amt_income_total_log\", \"risk_score\", \"months_employed\"]\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Build Transformer\n",
        "# ------------------------------------------------------------\n",
        "def build_transformer():\n",
        "    \n",
        "    transformers=[\n",
        "            (\"num\", StandardScaler(), numeric_cols)\n",
        "        ]\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
        "    \n",
        "    return preprocessor\n",
        "# ------------------------------------------------------------\n",
        "# 2. Drop Correlated Features\n",
        "# ------------------------------------------------------------\n",
        "# def drop_correlated_features(model_name, col_dic=column_dic):\n",
        "drop_cols = [\"days_birth\", \"amt_income_total\", \"years_employed\", \"flag_mobil\", \"code_gender\", \"flag_own_realty\", \"flag_own_car\", \"cnt_fam_members\"]\n",
        "    # if model_name in [\"SVC\", \"KNN\"]:\n",
        "    #     drop_cols.extend([\"cnt_children\", \"cnt_fam_members\"])\n",
        "    #     drop_cols.extend\n",
        "    # return drop_cols\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Feature Selection Model\n",
        "# ------------------------------------------------------------\n",
        "def build_feature_selector(model_name):\n",
        "    if model_name==\"SVC\":\n",
        "        return RFE(SVC(kernel='linear'), n_features_to_select=None, step=0.2, importance_getter='feature_importances_')\n",
        "    elif model_name==\"XGB\":\n",
        "        return SelectFromModel(XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42), threshold='median')\n",
        "    elif model_name==\"KNN\":\n",
        "        return SelectKBest(score_func=mutual_info_classif, k=10)\n",
        "# ------------------------------------------------------------\n",
        "# 4. Build Model\n",
        "# ------------------------------------------------------------\n",
        "def build_model(model_name):\n",
        "    if model_name == \"SVC\":\n",
        "        return \"SVM (Linear)\", SVC(kernel='linear', random_state=42)\n",
        "    elif model_name == \"XGB\":\n",
        "        return \"XGB Classifier\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "    elif model_name == \"KNN\":\n",
        "        return \"KNN\", KNeighborsClassifier()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model name\")\n",
        "    \n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. Model Training Pipeline\n",
        "# ------------------------------------------------------------\n",
        "def model_pipeline(model_name, train_df, test_df, target_col=\"label\", random_state=42):\n",
        "    # Drop correlated columns\n",
        "    drop_cols = [\"days_birth\", \"amt_income_total\", \"years_employed\", \"flag_mobil\", \"code_gender\", \"flag_own_realty\", \"flag_own_car\", \"cnt_fam_members\"]\n",
        "    train_df = train_df.drop(columns=drop_cols, errors='ignore')\n",
        "    test_df = test_df.drop(columns=drop_cols, errors='ignore')\n",
        "\n",
        "    # Split features and target\n",
        "    X_train_full = train_df.drop(columns=[target_col])\n",
        "    y_train_full = train_df[target_col]\n",
        "    X_test = test_df.drop(columns=[target_col])\n",
        "    y_test = test_df[target_col]\n",
        "\n",
        "    # Preprocessor\n",
        "    preprocessor = build_transformer()\n",
        "    \n",
        "    # Model\n",
        "    name, model = build_model(model_name)\n",
        "    print(f\"\\nTraining model: {name} using StratifiedKFold...\")\n",
        "\n",
        "    # Stratified K-Fold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "    acc_scores, f1_scores, roc_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full), 1):\n",
        "        X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
        "        y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"feature_selector\", build_feature_selector(model_name)),\n",
        "            (\"classifier\", model)\n",
        "        ])\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = pipeline.predict(X_val)\n",
        "        y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
        "        \n",
        "\n",
        "        acc_scores.append(accuracy_score(y_val, y_pred))\n",
        "        f1_scores.append(f1_score(y_val, y_pred))\n",
        "        roc_scores.append(roc_auc_score(y_val, y_proba))\n",
        "\n",
        "        print(f\"Fold {fold}: Accuracy={acc_scores[-1]:.3f}, F1={f1_scores[-1]:.3f}, ROC-AUC={roc_scores[-1]:.3f}\")\n",
        "\n",
        "    results = {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": np.mean(acc_scores),\n",
        "        \"f1_score\": np.mean(f1_scores),\n",
        "        \"roc_auc\": np.nanmean(roc_scores)\n",
        "    }\n",
        "\n",
        "    print(f\"\\nFinished training {name} across all folds.\")\n",
        "    print(f\"Average Accuracy: {results['accuracy']:.3f}, F1: {results['f1_score']:.3f}, ROC-AUC: {results['roc_auc']:.3f}\")\n",
        "\n",
        "    return results, X_train_full, y_train_full, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model: XGB Classifier using StratifiedKFold...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Accuracy=0.815, F1=0.205, ROC-AUC=0.580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2: Accuracy=0.809, F1=0.187, ROC-AUC=0.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 3: Accuracy=0.815, F1=0.203, ROC-AUC=0.582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 4: Accuracy=0.818, F1=0.209, ROC-AUC=0.577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5: Accuracy=0.810, F1=0.190, ROC-AUC=0.572\n",
            "\n",
            "Finished training XGB Classifier across all folds.\n",
            "Average Accuracy: 0.813, F1: 0.199, ROC-AUC: 0.579\n",
            "\n",
            "Training model: KNN using StratifiedKFold...\n",
            "Fold 1: Accuracy=0.773, F1=0.147, ROC-AUC=0.560\n",
            "Fold 2: Accuracy=0.767, F1=0.148, ROC-AUC=0.546\n",
            "Fold 3: Accuracy=0.770, F1=0.167, ROC-AUC=0.562\n",
            "Fold 4: Accuracy=0.769, F1=0.163, ROC-AUC=0.547\n",
            "Fold 5: Accuracy=0.763, F1=0.139, ROC-AUC=0.547\n",
            "\n",
            "Finished training KNN across all folds.\n",
            "Average Accuracy: 0.769, F1: 0.153, ROC-AUC: 0.552\n"
          ]
        }
      ],
      "source": [
        "models = [\"XGB\", \"KNN\"]\n",
        "for model in models:\n",
        "    # train_df, test_df = data_pipeline()\n",
        "    results_df, X_train, y_train, X_test, y_test = model_pipeline(model_name=model, \n",
        "        train_df=train, test_df=test, target_col=\"label\", random_state=42\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPVW1WKkh1bEXudRF2QGP07",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

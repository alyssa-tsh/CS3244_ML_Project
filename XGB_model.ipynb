{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyssa-tsh/CS3244_ML_Project/blob/main/cs3244_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U29HV8DBvCi"
      },
      "outputs": [],
      "source": [
        "from functions_ver2 import data_pipeline as data_pipeline_v2, scaling_std\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from model_func import build_model, build_feature_selector\n",
        "from visualize import plot_selected_features\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif, RFE, SelectFromModel\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data\n",
            "Splitting data\n",
            "Total unique accounts: 45985. Starting to find cutoff point\n",
            "Cutoff month where CDF reaches 80%: -10\n",
            "\n",
            "=== Split based on CDF 80% cutoff ===\n",
            "Cutoff month: -10 (10 months ago)\n",
            "Old accounts (≤ month -10): 37,210 (80.9%)\n",
            "New accounts (> month -10): 8,775 (19.1%)\n",
            "Ratio (old/new): 4.2405\n",
            "Splitting raw credit records\n",
            "Cleaning old accounts credit records - [Length: 996586]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/functions_ver2.py:260: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning new accounts credit records - [Length: 51989]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/functions_ver2.py:260: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  final_df = df.groupby(['id', 'origination_month']).apply(lambda x: pd.Series({\n",
            "/workspaces/CS3244_ML_Project/functions_ver2.py:184: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_dropped=df_sorted.groupby('id', group_keys=False).apply(keep_row)\n",
            "/workspaces/CS3244_ML_Project/functions_ver2.py:184: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_dropped=df_sorted.groupby('id', group_keys=False).apply(keep_row)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning credit data completed\n",
            "Splitting application dataset\n",
            "Cleaning old accounts application records - [Length: (29264, 18)]\n",
            "Cleaning new accounts appplication records, - [Length: (7193, 18)]\n",
            "Encoding\n",
            "Encoders: {'name_income_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'name_education_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'name_family_status': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'name_housing_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'occupation_type': OneHotEncoder(handle_unknown='ignore', sparse_output=False)}\n",
            "Encoding type: onehot\n",
            "Merging data\n",
            "Engineering target variable to label data\n",
            "Completed old accounts labelling\n",
            "Completed new accounts labelling\n",
            "Old accounts: (37210, 3)\n",
            "New accounts: (8775, 3)\n",
            "Old threshold: 0.20207707707707706\n",
            "New threshold: 0.5786182336182336\n",
            "Merging cleaned application and credit records\n",
            "Train shape: (29264, 63)\n",
            "Test shape: (7193, 63)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29264 entries, 0 to 29263\n",
            "Data columns (total 63 columns):\n",
            " #   Column                                             Non-Null Count  Dtype  \n",
            "---  ------                                             --------------  -----  \n",
            " 0   id                                                 29264 non-null  int64  \n",
            " 1   cnt_children                                       29264 non-null  int64  \n",
            " 2   amt_income_total                                   29264 non-null  float64\n",
            " 3   days_birth                                         29264 non-null  int64  \n",
            " 4   days_employed                                      29264 non-null  int64  \n",
            " 5   flag_mobil                                         29264 non-null  int64  \n",
            " 6   flag_work_phone                                    29264 non-null  int64  \n",
            " 7   flag_phone                                         29264 non-null  int64  \n",
            " 8   flag_email                                         29264 non-null  int64  \n",
            " 9   cnt_fam_members                                    29264 non-null  int64  \n",
            " 10  cnt_children_encoded                               29264 non-null  int64  \n",
            " 11  age                                                29264 non-null  int64  \n",
            " 12  age_binned_encoded                                 29264 non-null  int8   \n",
            " 13  months_employed                                    29264 non-null  int64  \n",
            " 14  years_employed                                     29264 non-null  int64  \n",
            " 15  employment_status_encoded                          29264 non-null  int64  \n",
            " 16  cnt_fam_members_encoded                            29264 non-null  int64  \n",
            " 17  gender_encoded                                     29264 non-null  int64  \n",
            " 18  flag_own_realty_encoded                            29264 non-null  int64  \n",
            " 19  flag_own_car_encoded                               29264 non-null  int64  \n",
            " 20  amt_income_total_log                               29264 non-null  float64\n",
            " 21  name_income_type_Commercial associate              29264 non-null  float64\n",
            " 22  name_income_type_Pensioner                         29264 non-null  float64\n",
            " 23  name_income_type_State servant                     29264 non-null  float64\n",
            " 24  name_income_type_Student                           29264 non-null  float64\n",
            " 25  name_income_type_Working                           29264 non-null  float64\n",
            " 26  name_education_type_Academic degree                29264 non-null  float64\n",
            " 27  name_education_type_Higher education               29264 non-null  float64\n",
            " 28  name_education_type_Incomplete higher              29264 non-null  float64\n",
            " 29  name_education_type_Lower secondary                29264 non-null  float64\n",
            " 30  name_education_type_Secondary / secondary special  29264 non-null  float64\n",
            " 31  name_family_status_Civil marriage                  29264 non-null  float64\n",
            " 32  name_family_status_Married                         29264 non-null  float64\n",
            " 33  name_family_status_Separated                       29264 non-null  float64\n",
            " 34  name_family_status_Single / not married            29264 non-null  float64\n",
            " 35  name_family_status_Widow                           29264 non-null  float64\n",
            " 36  name_housing_type_Co-op apartment                  29264 non-null  float64\n",
            " 37  name_housing_type_House / apartment                29264 non-null  float64\n",
            " 38  name_housing_type_Municipal apartment              29264 non-null  float64\n",
            " 39  name_housing_type_Office apartment                 29264 non-null  float64\n",
            " 40  name_housing_type_Rented apartment                 29264 non-null  float64\n",
            " 41  name_housing_type_With parents                     29264 non-null  float64\n",
            " 42  occupation_type_Accountants                        29264 non-null  float64\n",
            " 43  occupation_type_Cleaning staff                     29264 non-null  float64\n",
            " 44  occupation_type_Cooking staff                      29264 non-null  float64\n",
            " 45  occupation_type_Core staff                         29264 non-null  float64\n",
            " 46  occupation_type_Drivers                            29264 non-null  float64\n",
            " 47  occupation_type_HR staff                           29264 non-null  float64\n",
            " 48  occupation_type_High skill tech staff              29264 non-null  float64\n",
            " 49  occupation_type_IT staff                           29264 non-null  float64\n",
            " 50  occupation_type_Laborers                           29264 non-null  float64\n",
            " 51  occupation_type_Low-skill Laborers                 29264 non-null  float64\n",
            " 52  occupation_type_Managers                           29264 non-null  float64\n",
            " 53  occupation_type_Medicine staff                     29264 non-null  float64\n",
            " 54  occupation_type_Private service staff              29264 non-null  float64\n",
            " 55  occupation_type_Realty agents                      29264 non-null  float64\n",
            " 56  occupation_type_Sales staff                        29264 non-null  float64\n",
            " 57  occupation_type_Secretaries                        29264 non-null  float64\n",
            " 58  occupation_type_Security staff                     29264 non-null  float64\n",
            " 59  occupation_type_Unemployed                         29264 non-null  float64\n",
            " 60  occupation_type_Waiters/barmen staff               29264 non-null  float64\n",
            " 61  risk_score                                         29264 non-null  float64\n",
            " 62  label                                              29264 non-null  int64  \n",
            "dtypes: float64(43), int64(19), int8(1)\n",
            "memory usage: 13.9 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7193 entries, 0 to 7192\n",
            "Data columns (total 63 columns):\n",
            " #   Column                                             Non-Null Count  Dtype  \n",
            "---  ------                                             --------------  -----  \n",
            " 0   id                                                 7193 non-null   int64  \n",
            " 1   cnt_children                                       7193 non-null   int64  \n",
            " 2   amt_income_total                                   7193 non-null   float64\n",
            " 3   days_birth                                         7193 non-null   int64  \n",
            " 4   days_employed                                      7193 non-null   int64  \n",
            " 5   flag_mobil                                         7193 non-null   int64  \n",
            " 6   flag_work_phone                                    7193 non-null   int64  \n",
            " 7   flag_phone                                         7193 non-null   int64  \n",
            " 8   flag_email                                         7193 non-null   int64  \n",
            " 9   cnt_fam_members                                    7193 non-null   int64  \n",
            " 10  cnt_children_encoded                               7193 non-null   int64  \n",
            " 11  age                                                7193 non-null   int64  \n",
            " 12  age_binned_encoded                                 7193 non-null   int8   \n",
            " 13  months_employed                                    7193 non-null   int64  \n",
            " 14  years_employed                                     7193 non-null   int64  \n",
            " 15  employment_status_encoded                          7193 non-null   int64  \n",
            " 16  cnt_fam_members_encoded                            7193 non-null   int64  \n",
            " 17  gender_encoded                                     7193 non-null   int64  \n",
            " 18  flag_own_realty_encoded                            7193 non-null   int64  \n",
            " 19  flag_own_car_encoded                               7193 non-null   int64  \n",
            " 20  amt_income_total_log                               7193 non-null   float64\n",
            " 21  name_income_type_Commercial associate              7193 non-null   float64\n",
            " 22  name_income_type_Pensioner                         7193 non-null   float64\n",
            " 23  name_income_type_State servant                     7193 non-null   float64\n",
            " 24  name_income_type_Student                           7193 non-null   float64\n",
            " 25  name_income_type_Working                           7193 non-null   float64\n",
            " 26  name_education_type_Academic degree                7193 non-null   float64\n",
            " 27  name_education_type_Higher education               7193 non-null   float64\n",
            " 28  name_education_type_Incomplete higher              7193 non-null   float64\n",
            " 29  name_education_type_Lower secondary                7193 non-null   float64\n",
            " 30  name_education_type_Secondary / secondary special  7193 non-null   float64\n",
            " 31  name_family_status_Civil marriage                  7193 non-null   float64\n",
            " 32  name_family_status_Married                         7193 non-null   float64\n",
            " 33  name_family_status_Separated                       7193 non-null   float64\n",
            " 34  name_family_status_Single / not married            7193 non-null   float64\n",
            " 35  name_family_status_Widow                           7193 non-null   float64\n",
            " 36  name_housing_type_Co-op apartment                  7193 non-null   float64\n",
            " 37  name_housing_type_House / apartment                7193 non-null   float64\n",
            " 38  name_housing_type_Municipal apartment              7193 non-null   float64\n",
            " 39  name_housing_type_Office apartment                 7193 non-null   float64\n",
            " 40  name_housing_type_Rented apartment                 7193 non-null   float64\n",
            " 41  name_housing_type_With parents                     7193 non-null   float64\n",
            " 42  occupation_type_Accountants                        7193 non-null   float64\n",
            " 43  occupation_type_Cleaning staff                     7193 non-null   float64\n",
            " 44  occupation_type_Cooking staff                      7193 non-null   float64\n",
            " 45  occupation_type_Core staff                         7193 non-null   float64\n",
            " 46  occupation_type_Drivers                            7193 non-null   float64\n",
            " 47  occupation_type_HR staff                           7193 non-null   float64\n",
            " 48  occupation_type_High skill tech staff              7193 non-null   float64\n",
            " 49  occupation_type_IT staff                           7193 non-null   float64\n",
            " 50  occupation_type_Laborers                           7193 non-null   float64\n",
            " 51  occupation_type_Low-skill Laborers                 7193 non-null   float64\n",
            " 52  occupation_type_Managers                           7193 non-null   float64\n",
            " 53  occupation_type_Medicine staff                     7193 non-null   float64\n",
            " 54  occupation_type_Private service staff              7193 non-null   float64\n",
            " 55  occupation_type_Realty agents                      7193 non-null   float64\n",
            " 56  occupation_type_Sales staff                        7193 non-null   float64\n",
            " 57  occupation_type_Secretaries                        7193 non-null   float64\n",
            " 58  occupation_type_Security staff                     7193 non-null   float64\n",
            " 59  occupation_type_Unemployed                         7193 non-null   float64\n",
            " 60  occupation_type_Waiters/barmen staff               7193 non-null   float64\n",
            " 61  risk_score                                         7193 non-null   float64\n",
            " 62  label                                              7193 non-null   int64  \n",
            "dtypes: float64(43), int64(19), int8(1)\n",
            "memory usage: 3.4 MB\n",
            "None\n",
            "Completed X, y split\n",
            "Oversampling on original X_train, y_train started\n",
            "Final train and test processing completed generated successfully\n"
          ]
        }
      ],
      "source": [
        "X_train_std, y_train, X_train_smote_std, y_train_smote, X_train_smotetomek_std, y_train_smotetomek, X_train_cc_std, y_train_cc, X_test_std, y_test = data_pipeline_v2('onehot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def plot_selected_features(best_pipeline, X_columns, top_n=20):\n",
        "    \"\"\"\n",
        "    Plots selected features and their importances for a given trained pipeline.\n",
        "    \"\"\"\n",
        "    selector = best_pipeline.named_steps.get(\"feature_selector\", None)\n",
        "    model = best_pipeline.named_steps.get(\"classifier\", None)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # --- 1️⃣ Feature Selection Summary ---\n",
        "    if selector and hasattr(selector, \"get_support\"):\n",
        "        mask = selector.get_support()\n",
        "        selected = np.array(X_columns)[mask]\n",
        "        dropped = np.array(X_columns)[~mask]\n",
        "\n",
        "        print(f\"✅ Total features: {len(X_columns)} | Selected: {len(selected)} | Dropped: {len(dropped)}\")\n",
        "        print(f\"🧩 Example selected features: {selected[:10]}\")\n",
        "\n",
        "        # Visualize counts\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.barplot(\n",
        "            x=[\"Selected\", \"Dropped\"],\n",
        "            y=[len(selected), len(dropped)],\n",
        "            palette=[\"#00C49F\", \"#FF8042\"]\n",
        "        )\n",
        "        plt.title(\"Feature Selection Summary\")\n",
        "        plt.ylabel(\"Number of Features\")\n",
        "    else:\n",
        "        print(\"⚠️ No feature selector found; using all features.\")\n",
        "        selected = X_columns\n",
        "\n",
        "    # --- 2️⃣ Feature Importances ---\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        importances = model.feature_importances_\n",
        "        feat_df = (\n",
        "            pd.DataFrame({\n",
        "                \"feature\": selected,\n",
        "                \"importance\": importances\n",
        "            })\n",
        "            .sort_values(\"importance\", ascending=False)\n",
        "            .head(top_n)\n",
        "        )\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        sns.barplot(\n",
        "            data=feat_df,\n",
        "            x=\"importance\",\n",
        "            y=\"feature\",\n",
        "            palette=\"viridis\"\n",
        "        )\n",
        "        plt.title(f\"Top {top_n} Important Features\")\n",
        "        plt.xlabel(\"Importance\")\n",
        "        plt.ylabel(\"\")\n",
        "    else:\n",
        "        print(\"⚠️ Model does not expose `feature_importances_` attribute.\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def build_feature_selector_xgb():\n",
        "    \"\"\"Feature selector using XGBoost importance.\"\"\"\n",
        "    return SelectFromModel(XGBClassifier(eval_metric=\"logloss\", random_state=42), threshold='median')\n",
        "\n",
        "def threshold_tuning(y_true, y_proba):\n",
        "    \"\"\"Find optimal threshold maximizing F1 score.\"\"\"\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
        "    f1_scores = 2 * precision * recall / (precision + recall + 1e-6)\n",
        "    best_idx = np.argmax(f1_scores)\n",
        "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
        "    return best_threshold, f1_scores[best_idx]\n",
        "\n",
        "def plot_feature_importance(model, feature_names, top_n=20):\n",
        "    \"\"\"Plot top N features selected by SelectFromModel.\"\"\"\n",
        "    selector = model.named_steps['feature_selector']\n",
        "    clf = model.named_steps['classifier'].best_estimator_ \n",
        "    \n",
        "    selected_mask = selector.get_support()\n",
        "    selected_features = np.array(feature_names)[selected_mask]\n",
        "    feature_importances = clf.feature_importances_[selected_mask]\n",
        "    \n",
        "    df = pd.DataFrame({\n",
        "        'feature': selected_features,\n",
        "        'importance': feature_importances\n",
        "    }).sort_values('importance', ascending=False).head(top_n)\n",
        "    \n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.barh(df['feature'][::-1], df['importance'][::-1], color='skyblue')\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title('Top Selected Features')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def model_pipeline_xgb(X_train, y_train, X_test=None, y_test=None, n_splits=5, random_state=42):\n",
        "    print(\"Starting XGBoost pipeline with hyperparameter tuning and feature selection...\")\n",
        "    \n",
        "    # Compute imbalance weight\n",
        "    pos_weight = sum(y_train == 0) / sum(y_train == 1)\n",
        "    \n",
        "    # Hyperparameter space for RandomizedSearch\n",
        "    param_dist = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 5, 7, 9],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'gamma': [0, 0.1, 0.2, 0.5]\n",
        "    }\n",
        "\n",
        "    # Stratified K-Fold\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    fold_models, acc_scores, f1_scores, roc_scores = [], [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "        \n",
        "        # Base classifier\n",
        "        xgb = XGBClassifier(\n",
        "            objective='binary:logistic',\n",
        "            eval_metric='logloss',\n",
        "            random_state=random_state,\n",
        "            scale_pos_weight=pos_weight\n",
        "        )\n",
        "        \n",
        "        # Hyperparameter tuning\n",
        "        rnd_search = RandomizedSearchCV(\n",
        "            xgb, param_distributions=param_dist,\n",
        "            n_iter=20, scoring='f1', cv=3, verbose=0, n_jobs=-1, random_state=random_state\n",
        "        )\n",
        "        \n",
        "        pipeline = Pipeline([\n",
        "            ('feature_selector', build_feature_selector_xgb()),\n",
        "            ('classifier', rnd_search)\n",
        "        ])\n",
        "        \n",
        "        pipeline.fit(X_tr, y_tr)\n",
        "        \n",
        "        y_proba = pipeline.predict_proba(X_val)[:,1]\n",
        "        y_pred = pipeline.predict(X_val)\n",
        "        \n",
        "        acc_scores.append(accuracy_score(y_val, y_pred))\n",
        "        f1_scores.append(f1_score(y_val, y_pred))\n",
        "        roc_scores.append(roc_auc_score(y_val, y_proba))\n",
        "        fold_models.append(pipeline)\n",
        "        \n",
        "        print(f\"Fold {fold}: Accuracy={acc_scores[-1]:.3f}, F1={f1_scores[-1]:.3f}, ROC-AUC={roc_scores[-1]:.3f}\")\n",
        "\n",
        "    # Select best fold\n",
        "    best_fold = int(np.argmax(roc_scores))\n",
        "    best_model = fold_models[best_fold]\n",
        "    print(f\"\\nBest model from Fold {best_fold+1} selected (ROC-AUC={roc_scores[best_fold]:.3f})\")\n",
        "\n",
        "    # Test evaluation\n",
        "    results = {\n",
        "        'cv_accuracy': np.mean(acc_scores),\n",
        "        'cv_f1': np.mean(f1_scores),\n",
        "        'cv_roc_auc': np.mean(roc_scores)\n",
        "    }\n",
        "    \n",
        "    if X_test is not None and y_test is not None:\n",
        "        y_proba_test = best_model.predict_proba(X_test)[:,1]\n",
        "        best_threshold, best_f1_val = threshold_tuning(y_test, y_proba_test)\n",
        "        y_pred_test = (y_proba_test > best_threshold).astype(int)\n",
        "        \n",
        "        results.update({\n",
        "            'test_accuracy': accuracy_score(y_test, y_pred_test),\n",
        "            'test_f1': f1_score(y_test, y_pred_test),\n",
        "            'test_roc_auc': roc_auc_score(y_test, y_proba_test),\n",
        "            'test_best_threshold': best_threshold,\n",
        "            'test_f1_at_threshold': best_f1_val\n",
        "        })\n",
        "        \n",
        "        print(f\"\\nTest Results → Accuracy={results['test_accuracy']:.3f}, \"\n",
        "              f\"F1={results['test_f1']:.3f}, ROC-AUC={results['test_roc_auc']:.3f}, \"\n",
        "              f\"Best Threshold={best_threshold:.2f}, F1@Threshold={best_f1_val:.3f}\")\n",
        "        \n",
        "    return results, best_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using SMOTE - has the most balanced performance - selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting XGBoost pipeline with hyperparameter tuning and feature selection...\n",
            "Fold 1: Accuracy=0.790, F1=0.762, ROC-AUC=0.859\n",
            "Fold 2: Accuracy=0.805, F1=0.774, ROC-AUC=0.868\n",
            "Fold 3: Accuracy=0.793, F1=0.762, ROC-AUC=0.864\n",
            "Fold 4: Accuracy=0.793, F1=0.765, ROC-AUC=0.865\n",
            "Fold 5: Accuracy=0.815, F1=0.784, ROC-AUC=0.873\n",
            "\n",
            "Best model from Fold 5 selected (ROC-AUC=0.873)\n",
            "\n",
            "Test Results → Accuracy=0.249, F1=0.228, ROC-AUC=0.541, Best Threshold=0.18, F1@Threshold=0.228\n"
          ]
        }
      ],
      "source": [
        "best_model, metrics = model_pipeline_xgb(\n",
        "    X_train_smote_std, y_train_smote, X_test_std, y_test, n_splits=5, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using SMOTE - Cluster Centeroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model: XGB Classifier using StratifiedKFold...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:53:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Accuracy=0.737, F1=0.760, ROC-AUC=0.825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:53:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2: Accuracy=0.760, F1=0.781, ROC-AUC=0.852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:53:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 3: Accuracy=0.743, F1=0.760, ROC-AUC=0.847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:53:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 4: Accuracy=0.729, F1=0.754, ROC-AUC=0.817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:53:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5: Accuracy=0.743, F1=0.767, ROC-AUC=0.842\n",
            "Number of selected features: 28\n",
            "\n",
            "Best model from Fold 2 selected (ROC-AUC=0.852)\n",
            "\n",
            "Cross-Validation Summary → Accuracy: 0.742, F1: 0.764, ROC-AUC: 0.837\n",
            "\n",
            "Evaluating best-performing model on unseen test set...\n",
            "Test Results → Accuracy=0.426, F1=0.226, ROC-AUC=0.530\n"
          ]
        }
      ],
      "source": [
        "results_df, X_train, y_train, X_test, y_test = model_pipeline(model_name=\"XGB\", \n",
        "        X_train_full=X_train_cc_std, y_train_full=y_train_cc, X_test=X_test_std, y_test=y_test, target_col=\"label\", random_state=42\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using SMOTE_TOMEK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model: XGB Classifier using StratifiedKFold...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:45:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Accuracy=0.789, F1=0.759, ROC-AUC=0.857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:45:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2: Accuracy=0.815, F1=0.791, ROC-AUC=0.877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:45:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 3: Accuracy=0.809, F1=0.781, ROC-AUC=0.877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:45:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 4: Accuracy=0.786, F1=0.753, ROC-AUC=0.849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/CS3244_ML_Project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [05:45:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5: Accuracy=0.792, F1=0.762, ROC-AUC=0.862\n",
            "\n",
            "Best model from Fold 3 selected (ROC-AUC=0.877)\n",
            "\n",
            "Cross-Validation Summary → Accuracy: 0.798, F1: 0.769, ROC-AUC: 0.864\n",
            "\n",
            "Evaluating best-performing model on unseen test set...\n",
            "Test Results → Accuracy=0.688, F1=0.203, ROC-AUC=0.537\n"
          ]
        }
      ],
      "source": [
        "results_df, X_train, y_train, X_test, y_test = model_pipeline(model_name=\"XGB\", \n",
        "        X_train_full=X_train_smotetomek_std, y_train_full=y_train_smotetomek, X_test=X_test_std, y_test=y_test, target_col=\"label\", random_state=42\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting XGBoost pipeline with hyperparameter tuning and feature selection...\n",
            "Fold 1: Accuracy=0.791, F1=0.760, ROC-AUC=0.860\n",
            "Fold 2: Accuracy=0.818, F1=0.793, ROC-AUC=0.881\n",
            "Fold 3: Accuracy=0.811, F1=0.779, ROC-AUC=0.870\n",
            "Fold 4: Accuracy=0.792, F1=0.763, ROC-AUC=0.857\n",
            "Fold 5: Accuracy=0.792, F1=0.761, ROC-AUC=0.863\n",
            "\n",
            "Best model from Fold 2 selected (ROC-AUC=0.881)\n",
            "\n",
            "Test Results → Accuracy=0.275, F1=0.230, ROC-AUC=0.552, Best Threshold=0.17, F1@Threshold=0.231\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 5, got 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results_df, X_train, y_train, X_test, y_test = model_pipeline_xgb(\n\u001b[32m      2\u001b[39m         X_train_smotetomek_std,y_train_smotetomek, X_test_std, y_test, n_splits=\u001b[32m5\u001b[39m, random_state=\u001b[32m42\u001b[39m\n\u001b[32m      3\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 5, got 2)"
          ]
        }
      ],
      "source": [
        "best_model, metrics = model_pipeline_xgb(\n",
        "        X_train_smotetomek_std,y_train_smotetomek, X_test_std, y_test, n_splits=5, random_state=42\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPVW1WKkh1bEXudRF2QGP07",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
